# Awesome-Handwriting-Recognition
A curated list of resources dedicated to handwriting recognition
## 1. Papers

* *CODE means official code and CODE means not official code

### 1.1 Recognition Method

*Conf.* | *Date* | *Title* | *Highlight* | *code*/cite 
:---: | :---: |:--- | :---: | :---: 
cvpr2022 | 2022 |[Open-Set Text Recognition via Character-Context Decoupling](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf) | 待阅读 | [CODE]()
cvpr2022 | 2022 |[Pushing the Performance Limit of Scene Text Recognizer without Human Annotation](https://arxiv.org/pdf/2204.07714.pdf) | 待阅读 | [CODE]()

### 1.2 Data Generation

*Conf.* | *Date* | *Title* | *Highlight* | *code*/cite 
:---: | :---: |:--- | :---: | :---: 
cvpr2022 | 2022 |[Look Closer to Supervise Better:
One-Shot Font Generation via Component-Based Discriminator](https://arxiv.org/abs/2205.00146) | 待阅读 | [CODE]()
cvpr2022 | 2022 |[XMP-Font: Self-Supervised Cross-Modality Pre-training for
Few-Shot Font Generation](https://arxiv.org/abs/2204.05084) | 待阅读 | [CODE]()
cvpr2022 | 2022 |[XMP-Font: Self-Supervised Cross-Modality Pre-training for
Few-Shot Font Generation](https://arxiv.org/abs/2204.05084) | 待阅读 | [CODE]()
cvpr2022 | 2022 |[XMP-Font: Self-Supervised Cross-Modality Pre-training for
Few-Shot Font Generation](https://arxiv.org/abs/2204.05084) | 待阅读 | [CODE]()

## 2. Datasets

### 2.1 Introduction

|Dataset|Description|dataset link|
|----|----|----|
|PubLayNet|PubLayNet is a large dataset of document images, of which the layout is annotated with both bounding boxes and polygonal segmentations.The annotations are automatically generated by matching the PDF format and the XML format.The size of the dataset is comparable to established computer vision datasets, containing over 360 thousand document images, where typical document layout elements are annotated.|[PubLayNet](https://github.com/ibm-aur-nlp/PubLayNet)|
|DocBank|DocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.|[DocBank](https://github.com/doc-analysis/DocBank)|

### 2.2 Comparison of datasets for table structure recognition
TO DO

## 3. Other technical solutions
### 3.1 Relevant research institutions and scholars 
- [document AI](https://www.microsoft.com/en-us/research/project/document-ai/)
  
  - [Minghao Li](https://github.com/liminghao1630)
  - [Yiheng Xu](https://github.com/ranpox)
  
  
### 3.2 Related competitions
- [ICDAR 2021 Competition on Scientific Literature Parsing](https://github.com/IBM/ICDAR2021-SLP) ([Task A on Document Layout Recognition](https://aieval.draco.res.ibm.com/challenge/41/overview))
  
  - First Place Method: [Davar-Lab-OCR: VSR](https://github.com/hikopensource/DAVAR-Lab-OCR/tree/main/demo/text_layout/VSR)
  
  

### 3.3 Related lecture

* 2021

  * MSR: [Document AI: Benchmarks, Models and Applications (Presentation@ICDAR 2021)](https://www.microsoft.com/en-us/research/publication/document-ai-benchmarks-models-and-applications-presentationicdar-2021/)

  

 

